# rag/query.py
import google.generativeai as genai
import numpy as np

# ğŸ” ã“ã“ã«ã‚ãªãŸã®APIã‚­ãƒ¼ã‚’ç›´æ¥æ›¸ãï¼
genai.configure(api_key="AIzaSyC6MGicISfQ6CqIOTJfVs1lNadsm8N3VLQ")

# è»½é‡ã§ç„¡æ–™æ å‘ãã®ãƒ¢ãƒ‡ãƒ«
model = genai.GenerativeModel("gemini-1.5-flash")

def retrieve_and_answer(user_query, index, chunks, embed_model, top_k=3):
    query_vec = embed_model.encode([user_query])
    D, I = index.search(np.array(query_vec), top_k)
    context = "\n".join([chunks[i] for i in I[0]])

    prompt = f"""ä»¥ä¸‹ã®æ–‡æ›¸ã«åŸºã¥ã„ã¦è³ªå•ã«ç­”ãˆã¦ãã ã•ã„ã€‚

æ–‡æ›¸:
{context}

è³ªå•:
{user_query}
"""

    response = model.generate_content(prompt)
    return response.text
