# rag/query.py
import google.generativeai as genai
import numpy as np

# ğŸ” APIã‚­ãƒ¼ã¯ãƒ­ãƒ¼ã‚«ãƒ«ã§ã¯ç›´æ¥è¨˜è¿°ã—ã¦ã¾ã™ã€‚
genai.configure(api_key="")

# è»½é‡ã§ç„¡æ–™æ å‘ãã®ãƒ¢ãƒ‡ãƒ«
model = genai.GenerativeModel("gemini-1.5-flash")

def retrieve_and_answer(user_query, index, chunks, embed_model, top_k=3):
    query_vec = embed_model.encode([user_query])
    D, I = index.search(np.array(query_vec), top_k)
    context = "\n".join([chunks[i] for i in I[0]])

    prompt = f"""ä»¥ä¸‹ã®æ–‡æ›¸ã«åŸºã¥ã„ã¦è³ªå•ã«ç­”ãˆã¦ãã ã•ã„ã€‚

æ–‡æ›¸:
{context}

è³ªå•:
{user_query}
"""

    response = model.generate_content(prompt)
    return response.text
